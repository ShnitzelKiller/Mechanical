{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1232d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onshape.brepio as brepio\n",
    "import meshplot as mp\n",
    "import numpy as np\n",
    "from visualize import inspect, occ_to_mesh, emptyplot, add_axis\n",
    "import os\n",
    "from utils import adjacency_list_from_brepdata, homogenize, connected_components\n",
    "from pspart import Part\n",
    "import pandas as ps\n",
    "import intervaltree\n",
    "import pspart\n",
    "from intervaltree import IntervalTree, Interval\n",
    "import numpy.linalg as LA\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb6e317-4b46-4c86-a3d2-2c50ba914e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = '/fast/jamesn8/assembly_data/assembly_data_with_transforms.h5'\n",
    "assembly_df = ps.read_hdf(df_name,'assembly')\n",
    "part_df = ps.read_hdf(df_name,'part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4107ae-d4a8-4cea-be10-55130c0a32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mate_df = ps.read_hdf(df_name,'mate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06d8fd7-486c-4e0c-bba3-8ab7472ccd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_geometry = part_df.groupby('Assembly')['HasGeometry'].agg(all)\n",
    "assembly_df['HasAllGeometry'] = has_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de728a40-368f-46f3-95f8-a629f1d6c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = 'mate_statistics_heuristics'\n",
    "stride=1000\n",
    "dfs = []\n",
    "for i in range(17):\n",
    "    loc=i*stride\n",
    "    lastloc = (i+1)*stride-1\n",
    "    fname = f'{basename}_chunk_{loc}-{lastloc}.parquet'\n",
    "    if not os.path.isfile(fname):\n",
    "        break\n",
    "    dfs.append(ps.read_parquet(fname))\n",
    "mate_statistics_df = ps.concat(dfs, axis=0)\n",
    "del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda25e17-5d3c-438e-b1f9-a7970691873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mate_statistics_df['Assembly'] = mate_df['Assembly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f087f9-1089-4bb6-8214-b8e4131b7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcs_coincide = mate_statistics_df.groupby('Assembly').agg({'originsCoincide':all, 'mc1Exists':all, 'mc0Exists':all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d635126-e026-4020-8b79-f7533e77c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_df_filtered = assembly_df.loc[mcs_coincide[mcs_coincide['originsCoincide'] & mcs_coincide['mc0Exists'] & mcs_coincide['mc1Exists']].index]\n",
    "assembly_df_filtered = assembly_df_filtered[assembly_df_filtered['HasAllGeometry'] & (assembly_df_filtered['ConnectedComponents']==1) & (assembly_df_filtered['RigidPieces'] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1be4e00-6f69-498e-ab6d-215631b758c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/projects/grail/benjones/cadlab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f596a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = brepio.Loader(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aec35ea-fdc4-44ba-9989-0aa38feb8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mate_proposals(parts, epsilon_rel=0.001):\n",
    "    \"\"\"\n",
    "    Find list of (part1, part2, mc1, mc2) of probable mate locations given a list of (transform, pspart.Part)\n",
    "    `epsilon_fac`: fraction of maximum part dimension to use as epsilon for finding neighboring mate connectors\n",
    "    \"\"\"\n",
    "    maxdim = max([(part.bounding_box()[1]-part.bounding_box()[0]).max() for _, part in parts])\n",
    "    mc_locations = []\n",
    "    interval2part = []\n",
    "    part2offset = dict()\n",
    "    total_mcs = 0\n",
    "    for i,tf_part in enumerate(parts):\n",
    "        tf, part = tf_part\n",
    "        for mc in part.all_mate_connectors:\n",
    "            cs = mc.get_coordinate_system()\n",
    "            origin = tf[:3,:3] @ cs[:3,3] + tf[:3,3]\n",
    "            z_axis = tf[:3,:3] @ cs[:3,2]\n",
    "            mc_locations.append(np.concatenate([origin/maxdim, z_axis], axis=0))\n",
    "        new_total = total_mcs + len(part.all_mate_connectors)\n",
    "        interval2part.append((total_mcs, new_total, i))\n",
    "        part2offset[i] = total_mcs\n",
    "        total_mcs = new_total\n",
    "    nnhash = pspart.NNHash(mc_locations, 6, epsilon_rel)\n",
    "    tree = IntervalTree([Interval(l, u, d) for l, u, d in interval2part])\n",
    "    \n",
    "    proposals = set()\n",
    "    for i,loc in enumerate(mc_locations):\n",
    "        nearest = list(nnhash.get_nearest_points(loc))\n",
    "        part_index = next(iter(tree[i])).data\n",
    "        for j in nearest:\n",
    "            other_part_index = next(iter(tree[j])).data\n",
    "            if other_part_index != part_index:\n",
    "                pi1, pi2 = part_index, other_part_index\n",
    "                mci1, mci2 = i - part2offset[part_index], j - part2offset[other_part_index]\n",
    "                if pi1 > pi2:\n",
    "                    pi1, pi2 = pi2, pi1\n",
    "                    mci1, mci2 = mci2, mci1\n",
    "                proposals.add((pi1, pi2, parts[pi1][1].all_mate_connectors[mci1], parts[pi2][1].all_mate_connectors[mci2]))\n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec14180f-cef4-41d8-9010-0f0626bec80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from automate.lightning_models.simplified import SimplifiedJointModel\n",
    "from extension.ml import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2915b686-0629-47f7-b121-ba13b084d8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Metric` was deprecated since v1.3.0 in favor of `torchmetrics.metric.Metric`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n"
     ]
    }
   ],
   "source": [
    "predictor_location = Predictor('/projects/grail/benjones/cadlab/dalton_lightning_logs/real_all_fn_args_amounts_sum_directedhybridgcn12/version_0/checkpoints/epoch=46-val_auc=0.666113.ckpt')\n",
    "predictor_type = Predictor('/projects/grail/benjones/cadlab/dalton_lightning_logs/real_all_fn_args_amounts_sum_directedhybridgcn12_type/version_0/checkpoints/epoch=5-val_auc=0.948979.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e196b8a5-dd91-4311-9289-6ff9777fa5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_results_loc = dict()\n",
    "cached_results_type = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e01f2d55-62fd-4331-a248-d0e0eb846f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_assembly(geo, mates, results_loc):\n",
    "\n",
    "    find_mc = dict() #mate descriptors in global embedding -> (partOcc, mateconnector)\n",
    "    topo_offset = 0\n",
    "    for k in geo:\n",
    "        tf, part = geo[k]\n",
    "        N = part.num_topologies\n",
    "        for mc in part.all_mate_connectors:\n",
    "            key = (mc.orientation_inference.topology_ref + topo_offset, mc.location_inference.topology_ref + topo_offset, mc.location_inference.inference_type.value)\n",
    "            find_mc[key] = (k, mc)\n",
    "        topo_offset += N\n",
    "\n",
    "    best_mates = dict() #part pair -> mc pair\n",
    "    for i in range(results_loc[1].shape[1]):\n",
    "        occ1, mc1 = find_mc[tuple(results_loc[1][:3,i].numpy())]\n",
    "        occ2, mc2 = find_mc[tuple(results_loc[1][3:,i].numpy())]\n",
    "        if occ1 > occ2:\n",
    "            occ1, occ2 = occ2, occ1\n",
    "            mc1, mc2 = mc2, mc1\n",
    "        key = (occ1, occ2)\n",
    "        if key in best_mates:\n",
    "            continue\n",
    "        else:\n",
    "            best_mates[key] = (mc1, mc2, results_loc[0][i].item())\n",
    "            \n",
    "    return best_mates\n",
    "    \n",
    "def inference_statistics(geo, mates, best_mates, best_types, prob_threshold):\n",
    "    gt_mates = dict()\n",
    "    for mate in mates:\n",
    "        key = tuple(sorted((mate.matedEntities[0][0], mate.matedEntities[1][0])))\n",
    "        if key not in gt_mates:\n",
    "            gt_mates[key] = []\n",
    "        gt_mates[key].append(mate)\n",
    "    \n",
    "    gt_types = []\n",
    "    extra_mates = 0\n",
    "    missing_mates = 0\n",
    "    matched_mates = 0\n",
    "    missing_duplicates = 0\n",
    "    mate_distances = dict()\n",
    "    misclassified = 0\n",
    "    for j,pair in enumerate(best_mates):\n",
    "        mate = best_mates[pair]\n",
    "        gt_type = ['NONE']\n",
    "        if mate[2] >= prob_threshold:\n",
    "            if pair in gt_mates:\n",
    "                gt_type = [mate.type for mate in gt_mates[pair]]\n",
    "                tf = geo[pair[0]][0]\n",
    "                origin = tf[:3,:3] @ mate[0].get_coordinate_system()[:3,3] + tf[:3,3]\n",
    "                missing_duplicates += len(gt_mates[pair]) - 1\n",
    "                mate_types_i = [mate_types.index(gt_mate.type) for gt_mate in gt_mates[pair]]\n",
    "                matches = [mate_type_i == best_types[j] for mate_type_i in mate_types_i]\n",
    "                matched = any(matches)\n",
    "                if matched:\n",
    "                    matched_mates += 1\n",
    "                else:\n",
    "                    misclassified += 1\n",
    "                if matched:\n",
    "                    mate_index = matches.index(True)\n",
    "                    gt_origin = tf[:3,:3] @ gt_mates[pair][mate_index].matedEntities[0][1][0] + tf[:3,3]\n",
    "                    mate_distances[pair] = LA.norm(origin-gt_origin)\n",
    "                else:\n",
    "                    min_dist = np.inf\n",
    "                    for i in range(len(gt_mates[pair])):\n",
    "                        gt_origin = tf[:3,:3] @ gt_mates[pair][i].matedEntities[0][1][0] + tf[:3,3]\n",
    "                        dist = LA.norm(origin - gt_origin)\n",
    "                        if dist < min_dist:\n",
    "                            min_dist = dist\n",
    "                            mate_index = i\n",
    "                    mate_distances[pair] = min_dist\n",
    "            else:\n",
    "                extra_mates += 1\n",
    "        gt_types.append(gt_type)\n",
    "    for pair in gt_mates:\n",
    "        if pair not in best_mates or best_mates[pair][2] < prob_threshold:\n",
    "            missing_mates += 1\n",
    "    assert(len(gt_types) == len(best_types))\n",
    "    best_mates_keys = list(best_mates.keys())\n",
    "    print('inferred types:',[(mate_types[i[0]],i[1]) for j,i in enumerate(zip(best_types, gt_types)) if best_mates[best_mates_keys[j]][2] >= prob_threshold])\n",
    "    print(f'unmated parts: {missing_mates}\\nextra mated parts: {extra_mates}\\nmisclassified: {misclassified}\\nmissing duplicate mates: {missing_duplicates}\\ncorrectly classified mates: {matched_mates}\\nmate distances: {[mate_distances[k] for k in mate_distances]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d954d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a1d27a55424c668555a761dee833d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sample', options=(('58aace5054; 40 moving parts', '58aace5054540c1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mate_epsilon_rel = 0.001\n",
    "mate_types = ['PIN_SLOT', 'BALL', 'PARALLEL', 'SLIDER', 'REVOLUTE', 'CYLINDRICAL', 'PLANAR', 'FASTENED']\n",
    "@mp.interact(sample=[(f'{assembly_df_filtered.loc[ind][\"AssemblyPath\"][:10]}; {assembly_df_filtered.loc[ind][\"RigidPieces\"]} moving parts',assembly_df_filtered.loc[ind]['AssemblyPath']) for ind in assembly_df_filtered.index[:100]])\n",
    "def display_sample(sample):\n",
    "    print(sample)\n",
    "    try:\n",
    "        geo, mates = loader.load_flattened(sample + '.json', skipInvalid=True)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'File not found: {e}')\n",
    "        return\n",
    "    mate_counts = dict()\n",
    "    for mate in mates:\n",
    "        if mate.type in mate_counts:\n",
    "            mate_counts[mate.type] += 1\n",
    "        else:\n",
    "            mate_counts[mate.type] = 1\n",
    "    adj = homogenize(adjacency_list_from_brepdata(geo, mates))\n",
    "    num_connected = connected_components(adj)\n",
    "    num_rigid = connected_components(adj, connectionType='fasten')\n",
    "    if num_connected > 1:\n",
    "        print('warning:',num_connected,'connected components')\n",
    "    print('rigid pieces:',num_rigid)\n",
    "    print('total parts:',len(geo))\n",
    "    print(f'mates: {len(mates)}: ',mate_counts)\n",
    "\n",
    "    #choices = [(f'mate {i} ({mates[i].type}) ({mates[i].matedEntities[0][0]}, {mates[i].matedEntities[1][0]})',i) for i in range(len(mates)) if len(mates[i].matedEntities) == 2]\n",
    "    choices = [(f'mate {i} ({mates[i].type}) ({mates[i].name})',i) for i in range(len(mates)) if len(mates[i].matedEntities) == 2]\n",
    "    choices.append(('fullAssembly', -1))\n",
    "    choices.append(('inferAssembly', -2))\n",
    "    p = emptyplot()\n",
    "    badOccs = [k for k in geo if geo[k][1] is None or geo[k][1].V.shape[0] == 0]\n",
    "    if len(badOccs) > 0:\n",
    "        print(f'warning: {len(badOccs)} invalid parts!')\n",
    "    #for o in badOccs:\n",
    "    #    geo.pop(o)\n",
    "    @mp.interact(mate=choices, wireframe=False, show_parts=True)\n",
    "    def ff(mate, wireframe, show_parts):\n",
    "        if mate == -2:\n",
    "            if sample in cached_results_loc:\n",
    "                results_loc = cached_results_loc[sample]\n",
    "            else:\n",
    "                proposals = mate_proposals([geo[k] for k in geo], epsilon_rel = mate_epsilon_rel)\n",
    "                if len(proposals) > 0:\n",
    "                    results_loc = predictor_location.predict_assembly([geo[k][1] for k in geo], proposals)\n",
    "                    cached_results_loc[sample] = results_loc\n",
    "                else:\n",
    "                    print('no proposal MCs')\n",
    "                    return\n",
    "            \n",
    "            best_mates = infer_assembly(geo, mates, results_loc)\n",
    "            \n",
    "            if sample in cached_results_type:\n",
    "                results_type = cached_results_type[sample]\n",
    "            else:\n",
    "                occ2index = dict()\n",
    "                for i,occ in enumerate(geo):\n",
    "                    occ2index[occ] = i\n",
    "                results_type = predictor_type.predict_assembly_types([geo[k][1] for k in geo], [(occ2index[pair[0]], occ2index[pair[1]], best_mates[pair][0], best_mates[pair][1]) for pair in best_mates])\n",
    "                cached_results_type[sample] = results_type\n",
    "            \n",
    "            best_types = results_type.argmax(axis=1).numpy() #corresponds to best_mates\n",
    "            \n",
    "            @mp.interact(prob_threshold=widgets.BoundedFloatText(\n",
    "                value=.5,\n",
    "                min=0,\n",
    "                max=1.0,\n",
    "                step=0.1,\n",
    "                description='Probability threshold:',\n",
    "                disabled=False\n",
    "            ))\n",
    "            def show_result(prob_threshold):\n",
    "                inference_statistics(geo, mates, best_mates, best_types,prob_threshold)\n",
    "                inferred_mates = [brepio.Mate(mcs=best_mates[pair][:2], occIds=[pair[0], pair[1]], mateType=mate_types[best_types[i]], name=f'Mate {i}') for i,pair in enumerate(best_mates)]\n",
    "                inspect(geo, inferred_mates, p=p, wireframe=wireframe, show_parts=show_parts)\n",
    "        elif mate == -1:\n",
    "            print('displaying full assembly')\n",
    "            inspect(geo, mates, p=p, wireframe=wireframe, show_parts=show_parts)\n",
    "            #print('num mates:',len(mates))\n",
    "        elif len(mates[mate].matedEntities) == 2:\n",
    "            me = mates[mate].matedEntities\n",
    "            print('mated parts:',me[0][0],me[1][0])\n",
    "            if me[0][0] in badOccs or me[1][0] in badOccs:\n",
    "                print('invalid parts in mate')\n",
    "                return\n",
    "            occs = [geo[me[i][0]] for i in range(2)]\n",
    "            maxdim = max([max(geo[i[0]][1].V.max(0)-geo[i[0]][1].V.min(0)) for i in me if geo[i[0]][1].V.shape[0] > 0])\n",
    "\n",
    "            meshes = [occ_to_mesh(occ) for occ in occs]\n",
    "            if wireframe:\n",
    "                p.reset()\n",
    "                p.add_edges(meshes[0][0], meshes[0][1], shading={'line_color': 'red'})\n",
    "                p.add_edges(meshes[1][0], meshes[1][1], shading={'line_color': 'blue'})\n",
    "            else:\n",
    "                mp.plot(meshes[0][0], meshes[0][1],c=np.array([1, 0, 0]), plot=p)\n",
    "                p.add_mesh(meshes[1][0], meshes[1][1],c=np.array([0, 0, 1]))\n",
    "\n",
    "            for i in range(2):\n",
    "                tf = occs[i][0]\n",
    "                #print(f'matedCS origin {i}: {me[i][1][0]}')\n",
    "                newaxes = tf[:3, :3] @ me[i][1][1]\n",
    "                neworigin = tf[:3,:3] @ me[i][1][0] + tf[:3,3]\n",
    "                #print(f'transform {i}: {tf}')\n",
    "                print(f'origin {i}: {neworigin}')\n",
    "                add_axis(p, neworigin, newaxes[:,0], newaxes[:,1], newaxes[:,2], scale=maxdim/2)\n",
    "        else:\n",
    "            print(f'nonstandard mate with {len(me)} entities')\n",
    "    p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d51d15-16ba-4319-8eb6-a96c77198762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
