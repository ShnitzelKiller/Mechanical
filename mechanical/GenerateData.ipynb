{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5975519a-e887-4995-8b69-1e144588aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import meshplot as mp\n",
    "from IPython.display import JSON as DJSON\n",
    "from IPython.display import clear_output\n",
    "from pspart import Part\n",
    "from pspart import NNHash\n",
    "import os\n",
    "import pandas as ps\n",
    "from mate_proposals import mate_proposals, homogenize_frame\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import meshplot as mp\n",
    "import onshape.brepio as brepio\n",
    "import time\n",
    "from automate.data.data import UniformMateData\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bea5b3a-898c-4b9a-a8b1-75d8398c61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/projects/grail/benjones/cadlab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f887aec9-4b5b-498b-b5c1-9ca0911d0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '/fast/jamesn8/assembly_data/assembly_data_with_transforms_all.h5'\n",
    "assembly_df = ps.read_hdf(name,'assembly')\n",
    "mate_df = ps.read_hdf(name,'mate')\n",
    "part_df = ps.read_hdf(name,'part')\n",
    "mate_df['MateIndex'] = mate_df.index\n",
    "part_df['PartIndex'] = part_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac22affa-4a11-4b76-9558-54f430f9416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mate_df.set_index('Assembly', inplace=True)\n",
    "part_df.set_index('Assembly', inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7225ebf6-20b8-42aa-bca2-fb5133bbeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fully_connected_moving_no_multimates.txt','r') as f:\n",
    "    set_E_indices = [int(l.rstrip()) for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0e9e8a-82f3-49f2-b3a5-184a53c0d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mate_types = [\n",
    "            'PIN_SLOT',\n",
    "            'BALL',\n",
    "            'PARALLEL',\n",
    "            'SLIDER',\n",
    "            'REVOLUTE',\n",
    "            'CYLINDRICAL',\n",
    "            'PLANAR',\n",
    "            'FASTENED'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9bc8516-aa0e-4846-8b2b-99327bf2d261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_processed: 0/20845'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'num_processed: 1/20845'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'num_processed: 2/20845'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 36] File name too long: '/fast/jamesn8/assembly_data/mate_torch_data/de0155b7acbdde81620c0779_c23e613e49df9b61c54991d3_11b50d2755721e251405d166-MTDtQzeSq1A+4F2fU:Mpzcw2zh_N_wHy6iY:Ms58ZDAtXaLf7of4T:M_VZfLPJ0nskgK_x4:Mm0_dLYAgyo6uch9_-MTDtQzeSq1A+4F2fU:Mpzcw2zh_N_wHy6iY:Ms58ZDAtXaLf7of4T:M_VZfLPJ0nskgK_x4:M0qR3x_224bQEh9rf.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2052479/1081626719.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    307\u001b[0m                       mcs[1].orientation_inference.topology_ref, mcs[1].location_inference.topology_ref, mcs[1].location_inference.inference_type.value], dtype=torch.int)\n\u001b[1;32m    308\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmc_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{assembly_df.loc[ind,\"AssemblyPath\"]}-{part_subset.iloc[part_pair[0]][\"PartOccurrenceID\"].replace(\"/\",\"_\")}-{part_subset.iloc[part_pair[1]][\"PartOccurrenceID\"].replace(\"/\",\"_\")}.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 36] File name too long: '/fast/jamesn8/assembly_data/mate_torch_data/de0155b7acbdde81620c0779_c23e613e49df9b61c54991d3_11b50d2755721e251405d166-MTDtQzeSq1A+4F2fU:Mpzcw2zh_N_wHy6iY:Ms58ZDAtXaLf7of4T:M_VZfLPJ0nskgK_x4:Mm0_dLYAgyo6uch9_-MTDtQzeSq1A+4F2fU:Mpzcw2zh_N_wHy6iY:Ms58ZDAtXaLf7of4T:M_VZfLPJ0nskgK_x4:M0qR3x_224bQEh9rf.dat'"
     ]
    }
   ],
   "source": [
    "start_index = 1243\n",
    "\n",
    "outpath = '/fast/jamesn8/assembly_data/mate_torch_data'\n",
    "def LOG(st):\n",
    "    with open(logfile,'a') as logf:\n",
    "        logf.write(st + '\\n')\n",
    "statspath = '/fast/jamesn8/assembly_data/mate_torch_stats'\n",
    "logfile = os.path.join(statspath, 'log.txt')\n",
    "\n",
    "epsilon_rel = 0.001\n",
    "max_groups = 10\n",
    "max_mcs = 10000\n",
    "max_mc_pairs = 20000\n",
    "stride = 200\n",
    "last_mate_ckpt = 0\n",
    "last_ckpt = 0\n",
    "\n",
    "all_stats = []\n",
    "mate_stats = []\n",
    "processed_indices = []\n",
    "mate_indices = []\n",
    "run_start_time = time.time()\n",
    "for num_processed,ind in enumerate(set_E_indices[start_index:]):\n",
    "    stats = dict()\n",
    "    curr_mate_stats = []\n",
    "    #clear_output(wait=True)\n",
    "    display(f'num_processed: {num_processed}/{len(set_E_indices)}')\n",
    "\n",
    "    #1. spatially hash all MCFs (cache hash maps for each part for re-use with individual mates)\n",
    "    #2. for all mates, ensure that each MCF is represented (keep track of closest/equivalent MCFs, log percentage of assemblies for which this holds)\n",
    "    #3. get proposals, edit appropriate ones to true based on equivalence class computed per mated pair of parts (taking outer product of equivalent MCs on left and right)\n",
    "\n",
    "    LOG(f'{num_processed}/{len(set_E_indices)}: processing {assembly_df.loc[ind,\"AssemblyPath\"]} at {time.time()-run_start_time}')\n",
    "    \n",
    "    part_subset = part_df.loc[ind]\n",
    "    mate_subset = mate_df.loc[ind]\n",
    "    if mate_subset.ndim == 1:\n",
    "        mate_subset = ps.DataFrame([mate_subset], columns=mate_subset.keys())\n",
    "    \n",
    "    parts = []\n",
    "    part_paths = []\n",
    "    transforms = []\n",
    "    mcf_hashes = []\n",
    "    mco_hashes = []\n",
    "    mc_frames_all = []\n",
    "    occ_to_index = dict()\n",
    "    \n",
    "\n",
    "    #debug\n",
    "    #all_points = []\n",
    "    \n",
    "    for j in range(part_subset.shape[0]):\n",
    "        path = os.path.join(datapath, 'data/models', *[part_subset.iloc[j][k] for k in ['did','mv','eid','config']], f'{part_subset.iloc[j][\"PartId\"]}.xt')\n",
    "        assert(os.path.isfile(path))\n",
    "        part = Part(path)\n",
    "        part_paths.append(path)\n",
    "        parts.append(part)\n",
    "        tf = part_subset.iloc[j]['Transform']\n",
    "        transforms.append(tf)\n",
    "        occ_to_index[part_subset.iloc[j]['PartOccurrenceID']] = j\n",
    "    \n",
    "    \n",
    "    allpoints_transformed = [(tf[:3,:3] @ part.V.T + tf[:3,3,np.newaxis]).T for tf, part in zip(transforms, parts) if parts.V.shape[0] > 0]\n",
    "    if len(allpoints_transformed) == 0:\n",
    "        LOG('skipping due to no geometry')\n",
    "        continue\n",
    "    minPt = np.array([points.min(axis=0) for points in allpoints_transformed]).min(axis=0)\n",
    "    maxPt = np.array([points.max(axis=0) for points in allpoints_transformed]).max(axis=0)\n",
    "    \n",
    "    median = (minPt + maxPt)/2\n",
    "    dims = maxPt - minPt\n",
    "    maxdim = max(dims)\n",
    "    #maxdim = max([(part.bounding_box()[1]-part.bounding_box()[0]).max() for part in parts])\n",
    "    threshold = maxdim * epsilon_rel\n",
    "    \n",
    "    total_mcs = sum([len(part.all_mate_connectors) for part in parts])\n",
    "    stats['total_mates'] = mate_subset.shape[0]\n",
    "    stats['total_parts'] = len(parts)\n",
    "    stats['maxdim'] = maxdim\n",
    "    stats['total_mcs'] = total_mcs\n",
    "\n",
    "    for j in range(len(parts)):\n",
    "        part = parts[j]\n",
    "        tf = transforms[j]\n",
    "        mc_frames = []\n",
    "        mc_origins = []\n",
    "        for mc in part.all_mate_connectors:\n",
    "            cs = mc.get_coordinate_system()\n",
    "            frame = tf[:3,:3] @ cs[:3,:3]\n",
    "            frame_homogenized = homogenize_frame(frame, z_flip_only=True)\n",
    "            origin = tf[:3,:3] @ cs[:3,3] + tf[:3,3]\n",
    "            #all_points.append(origin)\n",
    "            rot = R.from_matrix(frame_homogenized).as_quat()\n",
    "            mc_origins.append(origin)\n",
    "            mc_frames.append(np.concatenate([origin/maxdim, rot]))\n",
    "        mc_frames_all.append(mc_frames)\n",
    "        frame_hash = NNHash(mc_frames, 7, epsilon_rel)\n",
    "        origin_hash = NNHash(mc_origins, 3, threshold)\n",
    "        #frame_hash = NNHash([mc_frame[:3] for mc_frame in mc_frames], 3, threshold)\n",
    "        mcf_hashes.append(frame_hash)\n",
    "        mco_hashes.append(origin_hash)\n",
    "\n",
    "    stats['invalid_frames'] = 0\n",
    "    stats['invalid_mates'] = 0\n",
    "    stats['invalid_coincident_origins'] = 0\n",
    "    stats['invalid_permuted_z'] = 0\n",
    "    \n",
    "    mate_matches = [] #list of (left MC IDs, right MC Ids) based on the type of mate\n",
    "    part_pair_to_mate = dict()\n",
    "\n",
    "    #all_points = np.array(all_points)\n",
    "    #p = mp.plot(all_points)\n",
    "    mate_invalids = []\n",
    "    for j in range(mate_subset.shape[0]):\n",
    "        matches = [set(), set()]\n",
    "        m_stats = dict()\n",
    "        part_indices = []\n",
    "        mate_invalid = False\n",
    "        for i in range(2):\n",
    "            occId = mate_subset.iloc[j][f'Part{i+1}']\n",
    "            partIndex = occ_to_index[occId]\n",
    "            part_indices.append(partIndex)\n",
    "            assert(part_subset.iloc[partIndex]['PartOccurrenceID'] == occId)\n",
    "            origin_local = mate_subset.iloc[j][f'Origin{i+1}']\n",
    "            frame_local = mate_subset.iloc[j][f'Axes{i+1}']\n",
    "            tf = transforms[partIndex]\n",
    "            origin = tf[:3,:3] @ origin_local + tf[:3,3]            \n",
    "            frame = tf[:3,:3] @ frame_local\n",
    "            frame_homogenized = homogenize_frame(frame, z_flip_only=True)\n",
    "            rot = R.from_matrix(frame_homogenized).as_quat()\n",
    "            mc_frame = np.concatenate([origin/maxdim, rot])\n",
    "            neighbors = mcf_hashes[partIndex].get_nearest_points(mc_frame)\n",
    "\n",
    "            for n in neighbors:\n",
    "                matches[i].add(n)\n",
    "            b_invalid = len(neighbors) == 0\n",
    "            b_num_matches = len(neighbors)\n",
    "            b_invalid_coincident_origins = False\n",
    "            b_invalid_permuted_z = False\n",
    "            if b_invalid:\n",
    "                stats['invalid_frames'] += 1\n",
    "                if not mate_invalid:\n",
    "                    stats['invalid_mates'] += 1\n",
    "                mate_invalid = True\n",
    "                origin_neighbors = mco_hashes[partIndex].get_nearest_points(origin)\n",
    "                if len(origin_neighbors) > 0:\n",
    "                    b_invalid_coincident_origins = True\n",
    "                    stats['invalid_coincident_origins'] += 1\n",
    "                    n = next(iter(origin_neighbors))\n",
    "                    c_frame = R.from_quat(mc_frames_all[partIndex][n][3:]).as_matrix()\n",
    "                    c_frame_homogenized = homogenize_frame(c_frame, z_flip_only=False)\n",
    "                    mate_frame_homogenized = homogenize_frame(frame, z_flip_only=False)\n",
    "                    dist = LA.norm(c_frame_homogenized - mate_frame_homogenized)\n",
    "\n",
    "                    if dist < threshold:\n",
    "                        b_invalid_permuted_z = True\n",
    "                        stats['invalid_permuted_z'] += 1\n",
    "            else:\n",
    "                mateType = mate_subset.iloc[j]['Type']\n",
    "                for k in range(len(mc_frames_all[partIndex])):\n",
    "                    c_origin_quat = mc_frames_all[partIndex][k]\n",
    "                    c_origin = c_origin_quat[:3]\n",
    "                    c_frame = R.from_quat(c_origin_quat[3:]).as_matrix()\n",
    "                    axisdist = LA.norm(c_frame[:,2] - frame_homogenized[:,2])\n",
    "                    if axisdist < epsilon_rel:\n",
    "                        if mateType == 'CYLINDRICAL' or mateType == 'SLIDER':\n",
    "                            c_origin_proj = c_origin @ c_frame[:,:2]\n",
    "                            origin_proj = (origin @ c_frame[:,:2])/maxdim\n",
    "                            projdist = LA.norm(c_origin_proj - origin_proj)\n",
    "                            if projdist < epsilon_rel:\n",
    "                                matches[i].add(k)\n",
    "                        elif mateType == 'PLANAR' or mateType == 'PARALLEL':\n",
    "                            c_origin_proj = c_origin.dot(c_frame[:,2])\n",
    "                            origin_proj = origin.dot(c_frame[:,2])/maxdim\n",
    "                            projdist = abs(c_origin_proj - origin_proj)\n",
    "                            if projdist < epsilon_rel:\n",
    "                                matches[i].add(k)\n",
    "                    \n",
    "            \n",
    "            m_stats[f'invalid_frame_{i}'] = b_invalid\n",
    "            m_stats[f'invalid_frame_{i}_coincident_origins'] = b_invalid_coincident_origins\n",
    "            m_stats[f'invalid_frame_{i}_permuted_z'] = b_invalid_permuted_z\n",
    "            m_stats[f'matches_frame_{i}'] = b_num_matches\n",
    "            m_stats[f'extra_matches_frame_{i}'] = len(matches[i]) - b_num_matches\n",
    "        m_stats['type'] = mate_subset.iloc[j]['Type']\n",
    "        m_stats['truncated_mc_pairs'] = False\n",
    "        curr_mate_stats.append(m_stats)\n",
    "        mate_indices.append(mate_subset.iloc[j]['MateIndex'])\n",
    "        mate_invalids.append(mate_invalid)\n",
    "        mate_matches.append(matches)\n",
    "        part_indices = tuple(sorted(part_indices))\n",
    "        part_pair_to_mate[part_indices] = j#mate_subset.iloc[j]['Type']\n",
    "    \n",
    "    if total_mcs <= max_mcs:\n",
    "        stats['false_part_pairs'] = 0\n",
    "        stats['missed_part_pairs'] = 0\n",
    "        stats['missed_mc_pairs'] = 0\n",
    "        #find assembly-level normalization matrix\n",
    "        p_normalized = np.identity(4, dtype=float)\n",
    "        p_normalized[:3,3] = -median\n",
    "        p_normalized[3,3] = maxdim #todo: figure out if this is double the factor\n",
    "        \n",
    "        #find match proposals\n",
    "        start = time.time()\n",
    "        proposals = mate_proposals(list(zip(transforms, parts)), epsilon_rel=epsilon_rel, max_groups=max_groups)\n",
    "        end = time.time()\n",
    "        stats['num_proposals'] = len(proposals)\n",
    "        stats['proposal_time'] = end-start\n",
    "        \n",
    "        #initialize pairs based on proposals\n",
    "        part_proposals = dict()\n",
    "        for proposal in proposals:\n",
    "            part_pair = proposal[:2]\n",
    "            if part_pair not in part_proposals:\n",
    "                mc_pair_dict = dict()\n",
    "                part_proposals[part_pair] = mc_pair_dict\n",
    "            else:\n",
    "                mc_pair_dict = part_proposals[part_pair]\n",
    "            mc_pair_dict[proposal[2:]] = -1 #mate type\n",
    "\n",
    "        #populate pairs with labels\n",
    "        #print('populating pairs with labels')\n",
    "        part_pair_found=False\n",
    "        mc_pair_found=False\n",
    "        for j in range(mate_subset.shape[0]):\n",
    "            if not mate_invalids[j]:\n",
    "                mate_type = mate_subset.iloc[j]['Type']\n",
    "                partIds = [occ_to_index[mate_subset.iloc[j][f'Part{i+1}']] for i in range(2)]\n",
    "                matches = mate_matches[j]\n",
    "\n",
    "                if partIds[0] > partIds[1]:\n",
    "                    partIds.reverse()\n",
    "                    matches = matches.copy()\n",
    "                    matches.reverse()\n",
    "                partIds = tuple(partIds)\n",
    "\n",
    "                if partIds in part_proposals:\n",
    "                    part_pair_found=True\n",
    "                    mc_pair_dict = part_proposals[partIds]\n",
    "                    for index1 in matches[0]:\n",
    "                        for index2 in matches[1]:\n",
    "                            mc_pair = index1, index2\n",
    "                            if mc_pair in mc_pair_dict:\n",
    "                                mc_pair_found=True\n",
    "                                mc_pair_dict[mc_pair] = mate_types.index(mate_type)\n",
    "            if not part_pair_found:\n",
    "                stats['missed_part_pairs'] += 1\n",
    "            if not mc_pair_found:\n",
    "                stats['missed_mc_pairs'] += 1\n",
    "            curr_mate_stats[j]['part_pair_found'] =  part_pair_found           \n",
    "            curr_mate_stats[j]['mc_pair_found'] =  mc_pair_found     \n",
    "        \n",
    "        #create data object for each part pair\n",
    "        #print('creating data object')\n",
    "        for part_pair in part_proposals:\n",
    "            mateIndex = -1\n",
    "            if part_pair in part_pair_to_mate:\n",
    "                mateIndex = part_pair_to_mate[part_pair]\n",
    "                mateType = mate_subset.iloc[mateIndex]['Type']\n",
    "            else:\n",
    "                mateType='FASTENED'\n",
    "                stats['false_part_pairs'] += 1\n",
    "            mc_pairs = part_proposals[part_pair]\n",
    "\n",
    "            if len(mc_pairs) > max_mc_pairs:\n",
    "                curr_mate_stats[mateIndex]['truncated_mc_pairs'] = True\n",
    "                mc_pairs_final=[]\n",
    "                mc_pairs_false=[]\n",
    "                for pair in mc_pairs:\n",
    "                    if mc_pairs[pair] >= 0:\n",
    "                        mc_pairs_final.append(pair)\n",
    "                    else:\n",
    "                        mc_pairs_false.append(pair)\n",
    "                N_true = len(mc_pairs_final)\n",
    "                N_remainder = max_mc_pairs - N_true\n",
    "                random.shuffle(mc_pairs_false)\n",
    "                for pair in mc_pairs_false[:N_remainder]:\n",
    "                    mc_pairs_final.append(pair)\n",
    "            else:\n",
    "                mc_pairs_final = mc_pairs\n",
    "            \n",
    "            part1 = parts[part_pair[0]]\n",
    "            part2 = parts[part_pair[1]]\n",
    "            or1, loc1, inf1 = part1.get_onshape_def_from_mc(part1.all_mate_connectors[0])\n",
    "            or2, loc2, inf2 = part2.get_onshape_def_from_mc(part2.all_mate_connectors[0])\n",
    "            data = UniformMateData(\n",
    "                part_paths[part_pair[0]],\n",
    "                or1,\n",
    "                loc1,\n",
    "                inf1,\n",
    "                p_normalized,\n",
    "                part_paths[part_pair[1]],\n",
    "                or2,\n",
    "                loc2,\n",
    "                inf2,\n",
    "                p_normalized,\n",
    "                mateType\n",
    "            )\n",
    "\n",
    "            data.mc_pairs = torch.empty((6, len(mc_pairs_final)), dtype=torch.int)\n",
    "            data.mc_pair_labels = torch.zeros(len(mc_pairs_final), dtype=torch.int)\n",
    "            all_mcs = [parts[part_pair[lr]].all_mate_connectors for lr in range(2)]\n",
    "            for k,p in enumerate(mc_pairs_final):\n",
    "                type_index = mc_pairs[p]\n",
    "                if type_index >= 0:\n",
    "                    data.mc_pair_labels[k] = 1\n",
    "                mcs = [all_mcs[lr][p[lr]] for lr in range(2)]\n",
    "                col = torch.tensor([mcs[0].orientation_inference.topology_ref, mcs[0].location_inference.topology_ref, mcs[0].location_inference.inference_type.value,\n",
    "                      mcs[1].orientation_inference.topology_ref, mcs[1].location_inference.topology_ref, mcs[1].location_inference.inference_type.value], dtype=torch.int)\n",
    "                data.mc_pairs[:,k] = col\n",
    "            #dataname = f'{assembly_df.loc[ind,\"AssemblyPath\"]}-{part_subset.iloc[part_pair[0]][\"PartOccurrenceID\"].replace(\"/\",\"_\")}-{part_subset.iloc[part_pair[1]][\"PartOccurrenceID\"].replace(\"/\",\"_\")}.dat'\n",
    "            dataname = f'{ind}-{part_subset.iloc[part_pair[0]][\"PartIndex\"]}-{part_subset.iloc[part_pair[1]][\"PartIndex\"]}.dat'\n",
    "            torch.save(data, os.path.join(outpath, dataname))\n",
    "            del data\n",
    "            \n",
    "    for stat in curr_mate_stats:\n",
    "        mate_stats.append(stat)\n",
    "    all_stats.append(stats)\n",
    "    processed_indices.append(ind)\n",
    "    \n",
    "    if (num_processed+1) % stride == 0:\n",
    "        \n",
    "        stat_df_mini = ps.DataFrame(all_stats[last_ckpt:], index=processed_indices[last_ckpt:])\n",
    "        mate_stat_df_mini = ps.DataFrame(mate_stats[last_mate_ckpt:], index=mate_indices[last_mate_ckpt:])\n",
    "        stat_df_mini.to_parquet(os.path.join(statspath, f'stats_{num_processed}.parquet'))\n",
    "        mate_stat_df_mini.to_parquet(os.path.join(statspath, f'mate_stats_{num_processed}.parquet'))\n",
    "        print(stat_df_mini.shape)\n",
    "        last_mate_ckpt = len(mate_indices)\n",
    "        last_ckpt = len(processed_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63604209-8a46-4c7f-a950-06dac45cc3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    154\n",
       "1.0     14\n",
       "2.0      4\n",
       "4.0      3\n",
       "3.0      1\n",
       "Name: missed_mc_pairs, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df_mini['missed_mc_pairs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb7771b0-7fba-4b26-9199-4a2e83ab16da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_indices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f83dad3a-7ef0-4907-96c4-f425e195f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7472"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_E_indices[1241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3757d0f8-1657-45c3-b0d5-e29d626910b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (917, 13), indices imply (918, 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes, consolidate)\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_form_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1775\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, verify_integrity)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (917, 13), indices imply (918, 13)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2025311/1897969861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessed_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmate_stats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmate_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmate_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    700\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     )\n\u001b[0;32m--> 702\u001b[0;31m                     mgr = arrays_to_mgr(\n\u001b[0m\u001b[1;32m    703\u001b[0m                         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"block\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         return create_block_manager_from_arrays(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         )\n",
      "\u001b[0;32m/fast/jamesn8/anaconda3/envs/torch3/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes, consolidate)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (917, 13), indices imply (918, 13)"
     ]
    }
   ],
   "source": [
    "stats_df = ps.DataFrame(all_stats, index=processed_indices)\n",
    "mate_stats_df = ps.DataFrame(mate_stats, index=mate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf94ffaf-b326-4b3f-b671-0c13d00ccc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af15fc9b-16da-4927-8869-329d5282ea05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3264"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part_proposals[(23,25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d31ca6c1-5c72-40f7-bb55-2dd95f93b1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[          0,           0,         113,           0],\n",
       "        [-1221734976,       21869,  -609547136,       32600],\n",
       "        [        248,         248,           0,           0]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty((3, 4), dtype=torch.int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c94b07-15f6-4283-9670-f184b5e5e2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
